{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. n-gram 기반 통계 언어 모델 구현\n",
    "\n",
    "이 노트북에서는 n-gram 모델을 구현하여 통계적 언어 모델의 기본 원리를 학습합니다.\n",
    "\n",
    "## 학습 목표\n",
    "- n-gram 모델의 수학적 원리 이해하기\n",
    "- 동시출현 행렬(co-occurrence matrix) 구축하기\n",
    "- 조건부 확률 $P(w_i | w_{i-1})$ 계산하기\n",
    "- 손실 함수(Negative Log Likelihood) 구현하고 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 전처리 결과 불러오기\n",
    "\n",
    "이전 노트북에서 저장한 전처리 결과를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 결과를 성공적으로 불러왔습니다.\n",
      "어휘 사전 크기: 59 단어\n",
      "문장 수: 10\n"
     ]
    }
   ],
   "source": [
    "# 전처리 결과 불러오기\n",
    "try:\n",
    "    with open('preprocessing_results.pkl', 'rb') as f:\n",
    "        preprocessing_results = pickle.load(f)\n",
    "    \n",
    "    tokenized_corpus = preprocessing_results['tokenized_corpus']\n",
    "    word_to_id = preprocessing_results['word_to_id']\n",
    "    id_to_word = preprocessing_results['id_to_word']\n",
    "    word_counts = preprocessing_results['word_counts']\n",
    "    \n",
    "    print(\"전처리 결과를 성공적으로 불러왔습니다.\")\n",
    "    print(f\"어휘 사전 크기: {len(word_to_id)} 단어\")\n",
    "    print(f\"문장 수: {len(tokenized_corpus)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"전처리 결과 파일을 찾을 수 없습니다. 먼저 '1_corpus_preprocessing.ipynb'를 실행해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 n-gram 추출 함수 구현\n",
    "\n",
    "텍스트에서 n-gram을 추출하는 함수를 구현합니다. n-gram은 연속된 n개의 단어 시퀀스를 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추출된 bigram 수: 60\n",
      "추출된 trigram 수: 50\n",
      "\n",
      "샘플 bigram 5개:\n",
      "('자연어', '처리는')\n",
      "('처리는', '컴퓨터가')\n",
      "('컴퓨터가', '인간의')\n",
      "('인간의', '언어를')\n",
      "('언어를', '이해하고')\n"
     ]
    }
   ],
   "source": [
    "def extract_ngrams(sentences, n=2):\n",
    "    \"\"\"문장들에서 n-gram을 추출하는 함수\n",
    "    \n",
    "    Args:\n",
    "        sentences: 토큰화된 문장 목록\n",
    "        n: n-gram의 n (기본값: 2, 즉 bigram)\n",
    "        \n",
    "    Returns:\n",
    "        추출된 n-gram 목록\n",
    "    \"\"\"\n",
    "    all_ngrams = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # 문장의 길이가 n보다 작으면 n-gram을 추출할 수 없음\n",
    "        if len(sentence) < n:\n",
    "            continue\n",
    "            \n",
    "        # n-gram 추출\n",
    "        sentence_ngrams = [tuple(sentence[i:i+n]) for i in range(len(sentence) - n + 1)]\n",
    "        all_ngrams.extend(sentence_ngrams)\n",
    "    \n",
    "    return all_ngrams\n",
    "\n",
    "# bigram (n=2) 추출 예시\n",
    "bigrams = extract_ngrams(tokenized_corpus, n=2)\n",
    "# trigram (n=3) 추출 예시\n",
    "trigrams = extract_ngrams(tokenized_corpus, n=3)\n",
    "\n",
    "print(f\"추출된 bigram 수: {len(bigrams)}\")\n",
    "print(f\"추출된 trigram 수: {len(trigrams)}\")\n",
    "print(\"\\n샘플 bigram 5개:\")\n",
    "for bigram in bigrams[:5]:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "샘플 trigram 5개:\n",
      "('자연어', '처리는', '컴퓨터가')\n",
      "('처리는', '컴퓨터가', '인간의')\n",
      "('컴퓨터가', '인간의', '언어를')\n",
      "('인간의', '언어를', '이해하고')\n",
      "('언어를', '이해하고', '처리하는')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n샘플 trigram 5개:\")\n",
    "for trigram in trigrams[:5]:\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 동시출현 행렬(Co-occurrence Matrix) 구축\n",
    "\n",
    "bigram에 대한 동시출현 행렬을 구축합니다. 이 행렬은 단어 쌍 $(w_{i-1}, w_i)$의 출현 빈도를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시출현 행렬 크기: (59, 59)\n",
      "총 동시출현 빈도: 60\n",
      "0이 아닌 원소 수: 58\n"
     ]
    }
   ],
   "source": [
    "def build_cooccurrence_matrix(ngrams, vocab_size, word_to_id):\n",
    "    \"\"\"n-gram에서 동시출현 행렬을 구축하는 함수\n",
    "    \n",
    "    Args:\n",
    "        ngrams: n-gram 목록\n",
    "        vocab_size: 어휘 사전 크기\n",
    "        word_to_id: 단어-ID 매핑 딕셔너리\n",
    "        \n",
    "    Returns:\n",
    "        동시출현 행렬 (numpy array)\n",
    "    \"\"\"\n",
    "    # 동시출현 행렬 초기화 (모든 원소가 0인 행렬)\n",
    "    cooccurrence_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    # n-gram에서 동시출현 빈도 계산\n",
    "    for ngram in ngrams:\n",
    "        # 첫 번째 단어는 행 인덱스, 두 번째 단어는 열 인덱스\n",
    "        # bigram일 경우 (w_{i-1}, w_i)\n",
    "        prev_word, curr_word = ngram[0], ngram[1]\n",
    "        prev_id, curr_id = word_to_id[prev_word], word_to_id[curr_word]\n",
    "        \n",
    "        # 해당 단어 쌍의 동시출현 빈도 증가\n",
    "        cooccurrence_matrix[prev_id, curr_id] += 1\n",
    "    \n",
    "    return cooccurrence_matrix\n",
    "\n",
    "# bigram에 대한 동시출현 행렬 구축\n",
    "vocab_size = len(word_to_id)\n",
    "cooccurrence_matrix = build_cooccurrence_matrix(bigrams, vocab_size, word_to_id)\n",
    "\n",
    "print(f\"동시출현 행렬 크기: {cooccurrence_matrix.shape}\")\n",
    "print(f\"총 동시출현 빈도: {cooccurrence_matrix.sum()}\")\n",
    "print(f\"0이 아닌 원소 수: {np.count_nonzero(cooccurrence_matrix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 조건부 확률 $P(w_i | w_{i-1})$ 계산\n",
    "\n",
    "동시출현 행렬을 사용하여 조건부 확률 $P(w_i | w_{i-1})$을 계산합니다. 이는 이전 단어 $w_{i-1}$이 주어졌을 때 현재 단어 $w_i$가 나타날 확률입니다.\n",
    "\n",
    "$$P(w_i | w_{i-1}) = \\frac{C(w_{i-1}, w_i)}{C(w_{i-1})}$$\n",
    "\n",
    "여기서 $C(w_{i-1}, w_i)$는 단어 쌍 $(w_{i-1}, w_i)$의 출현 빈도이고, $C(w_{i-1})$은 단어 $w_{i-1}$의 출현 빈도입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조건부 확률 행렬 크기: (59, 59)\n",
      "각 행의 합이 1인지 확인 (0이 아닌 행만): True\n"
     ]
    }
   ],
   "source": [
    "def calculate_conditional_probabilities(cooccurrence_matrix, vocab_size):\n",
    "    \"\"\"동시출현 행렬에서 조건부 확률 P(w_i | w_{i-1})을 계산하는 함수 (Laplace Smoothing 적용)\n",
    "    \n",
    "    Args:\n",
    "        cooccurrence_matrix: 동시출현 행렬 (numpy array)\n",
    "        vocab_size: 어휘 크기 V\n",
    "        \n",
    "    Returns:\n",
    "        조건부 확률 행렬\n",
    "    \"\"\"\n",
    "    # 기존: smoothing 없이 계산\n",
    "    # 각 행의 합 계산 (각 단어 w_{i-1}의 출현 빈도)\n",
    "    # row_sums = cooccurrence_matrix.sum(axis=1, keepdims=True)\n",
    "    # 0으로 나누는 것을 방지하기 위해 0인 경우 1로 변경\n",
    "    # row_sums[row_sums == 0] = 1\n",
    "    # 조건부 확률 계산: P(w_i | w_{i-1}) = C(w_{i-1}, w_i) / C(w_{i-1})\n",
    "    # conditional_probabilities = cooccurrence_matrix / row_sums\n",
    "\n",
    "    # Laplace Smoothing 적용\n",
    "    smoothed_matrix = cooccurrence_matrix + 1\n",
    "    row_sums = smoothed_matrix.sum(axis=1, keepdims=True)  # 각 행 합 + V가 반영됨\n",
    "    conditional_probabilities = smoothed_matrix / row_sums\n",
    "\n",
    "    return conditional_probabilities\n",
    "\n",
    "\n",
    "# 조건부 확률 계산\n",
    "conditional_probabilities = calculate_conditional_probabilities(cooccurrence_matrix, vocab_size)\n",
    "\n",
    "print(f\"조건부 확률 행렬 크기: {conditional_probabilities.shape}\")\n",
    "# 0이 아닌 행(단어가 최소 한 번 이상 등장한 경우)의 합은 1이어야 함\n",
    "non_zero_rows = cooccurrence_matrix.sum(axis=1) > 0\n",
    "print(f\"각 행의 합이 1인지 확인 (0이 아닌 행만): {np.allclose(conditional_probabilities[non_zero_rows].sum(axis=1), 1.0, rtol=1e-10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 조건부 확률 시각화\n",
    "\n",
    "특정 단어들에 대한 조건부 확률을 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: koreanize_matplotlib in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: matplotlib in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from koreanize_matplotlib) (3.10.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (4.57.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (10.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (3.2.3)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (2.2.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (1.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from matplotlib->koreanize_matplotlib) (1.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/martin/.asdf/installs/python/3.10.15/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->koreanize_matplotlib) (1.17.0)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install koreanize_matplotlib\n",
    "import koreanize_matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 '상위'를 어휘 사전에서 찾을 수 없습니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 '상위'를 어휘 사전에서 찾을 수 없습니다.\n",
      "\n",
      "[로그 확률 출력: P(w_i | 상위)]\n",
      "log(P(자연어 | 상위)) = -4.07753744390572\n",
      "log(P(처리는 | 상위)) = -4.07753744390572\n",
      "log(P(기술입니다 | 상위)) = -4.07753744390572\n",
      "log(P(처리의 | 상위)) = -4.07753744390572\n",
      "log(P(모델은 | 상위)) = -4.07753744390572\n",
      "log(P(워드 | 상위)) = -4.07753744390572\n",
      "log(P(단어를 | 상위)) = -4.07753744390572\n",
      "log(P(컴퓨터가 | 상위)) = -4.07753744390572\n",
      "log(P(인간의 | 상위)) = -4.07753744390572\n",
      "log(P(언어를 | 상위)) = -4.07753744390572\n",
      "log(P(이해하고 | 상위)) = -4.07753744390572\n",
      "log(P(처리하는 | 상위)) = -4.07753744390572\n",
      "log(P(컴퓨터는 | 상위)) = -4.07753744390572\n",
      "log(P(처리를 | 상위)) = -4.07753744390572\n",
      "log(P(통해 | 상위)) = -4.07753744390572\n",
      "log(P(텍스트를 | 상위)) = -4.07753744390572\n",
      "log(P(분석하고 | 상위)) = -4.07753744390572\n",
      "log(P(의미를 | 상위)) = -4.07753744390572\n",
      "log(P(추출합니다 | 상위)) = -4.07753744390572\n",
      "log(P(인공지능과 | 상위)) = -4.07753744390572\n",
      "log(P(기계학습은 | 상위)) = -4.07753744390572\n",
      "log(P(핵심 | 상위)) = -4.07753744390572\n",
      "log(P(딥러닝 | 상위)) = -4.07753744390572\n",
      "log(P(처리 | 상위)) = -4.07753744390572\n",
      "log(P(성능을 | 상위)) = -4.07753744390572\n",
      "log(P(크게 | 상위)) = -4.07753744390572\n",
      "log(P(향상시켰습니다 | 상위)) = -4.07753744390572\n",
      "log(P(임베딩은 | 상위)) = -4.07753744390572\n",
      "log(P(벡터 | 상위)) = -4.07753744390572\n",
      "log(P(공간에 | 상위)) = -4.07753744390572\n",
      "log(P(표현하는 | 상위)) = -4.07753744390572\n",
      "log(P(방법입니다 | 상위)) = -4.07753744390572\n",
      "log(P(GloVe와 | 상위)) = -4.07753744390572\n",
      "log(P(Word2Vec은 | 상위)) = -4.07753744390572\n",
      "log(P(대표적인 | 상위)) = -4.07753744390572\n",
      "log(P(임베딩 | 상위)) = -4.07753744390572\n",
      "log(P(알고리즘입니다 | 상위)) = -4.07753744390572\n",
      "log(P(언어 | 상위)) = -4.07753744390572\n",
      "log(P(다음 | 상위)) = -4.07753744390572\n",
      "log(P(예측하는 | 상위)) = -4.07753744390572\n",
      "log(P(모델입니다 | 상위)) = -4.07753744390572\n",
      "log(P(ngram은 | 상위)) = -4.07753744390572\n",
      "log(P(연속된 | 상위)) = -4.07753744390572\n",
      "log(P(n개의 | 상위)) = -4.07753744390572\n",
      "log(P(단어 | 상위)) = -4.07753744390572\n",
      "log(P(시퀀스를 | 상위)) = -4.07753744390572\n",
      "log(P(의미합니다 | 상위)) = -4.07753744390572\n",
      "log(P(기계 | 상위)) = -4.07753744390572\n",
      "log(P(번역 | 상위)) = -4.07753744390572\n",
      "log(P(감성 | 상위)) = -4.07753744390572\n",
      "log(P(분석 | 상위)) = -4.07753744390572\n",
      "log(P(정보 | 상위)) = -4.07753744390572\n",
      "log(P(추출 | 상위)) = -4.07753744390572\n",
      "log(P(등에 | 상위)) = -4.07753744390572\n",
      "log(P(활용됩니다 | 상위)) = -4.07753744390572\n",
      "log(P(텍스트 | 상위)) = -4.07753744390572\n",
      "log(P(전처리는 | 상위)) = -4.07753744390572\n",
      "log(P(첫 | 상위)) = -4.07753744390572\n",
      "log(P(단계입니다 | 상위)) = -4.07753744390572\n",
      "Next Word (w_i)  P(w_i | w_{i-1}='상위')\n",
      "          단계입니다               0.016949\n",
      "             통해               0.016949\n",
      "        향상시켰습니다               0.016949\n",
      "             크게               0.016949\n",
      "            성능을               0.016949\n"
     ]
    }
   ],
   "source": [
    "def visualize_conditional_probabilities(conditional_probabilities, id_to_word, prev_words, top_n=5):\n",
    "    \"\"\"특정 단어들에 대한 조건부 확률을 시각화하는 함수\n",
    "    \n",
    "    Args:\n",
    "        conditional_probabilities: 조건부 확률 행렬\n",
    "        id_to_word: ID-단어 매핑 딕셔너리\n",
    "        prev_words: 이전 단어 목록\n",
    "        top_n: 상위 몇 개의 확률을 표시할지 결정\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(prev_words), 1, figsize=(10, 4 * len(prev_words)))\n",
    "    if len(prev_words) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, prev_word in enumerate(prev_words):\n",
    "        # 이전 단어의 ID\n",
    "        try:\n",
    "            prev_id = word_to_id[prev_word]\n",
    "        except KeyError:\n",
    "            print(f\"단어 '{prev_word}'를 어휘 사전에서 찾을 수 없습니다.\")\n",
    "            # continue\n",
    "            prev_id = 999\n",
    "            prev_word = \"UNK\"\n",
    "        if( prev_id == 999):\n",
    "            probs = np.zeros(shape=(len(word_to_id),))\n",
    "        else:\n",
    "            probs = conditional_probabilities[prev_id]\n",
    "        # 해당 단어의 조건부 확률 행 추출\n",
    "        # probs = conditional_probabilities[prev_id]\n",
    "        \n",
    "        # 확률이 높은 상위 top_n개 단어 선택\n",
    "        top_indices = np.argsort(probs)[-top_n:][::-1]\n",
    "        top_probs = probs[top_indices]\n",
    "        top_words = [id_to_word[idx] for idx in top_indices]\n",
    "        \n",
    "        # 시각화\n",
    "        axes[i].barh(top_words, top_probs)\n",
    "        axes[i].set_title(f\"P(w_i | w_{{i-1}}='{prev_word}')\", fontsize=14)\n",
    "        axes[i].set_xlabel('확률', fontsize=12)\n",
    "        axes[i].set_ylabel('다음 단어 (w_i)', fontsize=12)\n",
    "        axes[i].invert_yaxis()  # 확률이 높은 단어를 위쪽에 표시\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 특정 단어들에 대한 조건부 확률 시각화\n",
    "# 가장 빈도가 높은 단어들 중 일부 선택\n",
    "most_common_words = [word for word, _ in word_counts.most_common(5)]\n",
    "# visualize_conditional_probabilities(conditional_probabilities, id_to_word, most_common_words)\n",
    "most_common_words = [\"상위\"] # 학습에 사용되지 않은 단어로 대체\n",
    "visualize_conditional_probabilities(conditional_probabilities, id_to_word, most_common_words)\n",
    "\n",
    "# 결과를 pandas DataFrame으로 변환하여 테이블 형태로 확인\n",
    "def display_conditional_probability_table(conditional_probabilities, word_to_id, id_to_word, prev_word, top_n=5):\n",
    "    \"\"\"특정 단어에 대한 조건부 확률을 테이블 형태로 표시하는 함수\"\"\"    \n",
    "    try:\n",
    "        prev_id = word_to_id[prev_word]\n",
    "    except KeyError:\n",
    "        print(f\"단어 '{prev_word}'를 어휘 사전에서 찾을 수 없습니다.\")\n",
    "        # return None\n",
    "        prev_id = 999 # 대체 ID\n",
    "    \n",
    "    if( prev_id == 999):\n",
    "        probs = np.ones(shape=(len(word_to_id),))  # 먼저 1로 채우고\n",
    "        probs = probs / np.sum(probs)              # 그걸 정규화해서 확률 분포로 만듦\n",
    "    else:\n",
    "        probs = conditional_probabilities[prev_id]\n",
    "    top_indices = np.argsort(probs)[-top_n:][::-1]\n",
    "    top_probs = probs[top_indices]\n",
    "    top_words = [id_to_word[idx] for idx in top_indices]\n",
    "    \n",
    "    # DataFrame 생성\n",
    "    df = pd.DataFrame({\n",
    "        'Next Word (w_i)': top_words,\n",
    "        f'P(w_i | w_{{i-1}}=\\'{prev_word}\\')': top_probs\n",
    "    })\n",
    "\n",
    "    # log 확률 시도 (삽질 유도)\n",
    "    print(f\"\\n[로그 확률 출력: P(w_i | {prev_word})]\")\n",
    "    for idx, prob in enumerate(probs):\n",
    "        try:\n",
    "            logp = np.log(prob)\n",
    "        except:\n",
    "            logp = float('-inf')\n",
    "        print(f\"log(P({id_to_word[idx]} | {prev_word})) = {logp}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 예시: 첫 번째 단어에 대한 조건부 확률 테이블\n",
    "example_word = most_common_words[0]\n",
    "cond_prob_table = display_conditional_probability_table(conditional_probabilities, word_to_id, id_to_word, example_word)\n",
    "if cond_prob_table is not None:\n",
    "    print(cond_prob_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Negative Log Likelihood Loss 구현\n",
    "\n",
    "n-gram 모델의 성능을 평가하기 위해 Negative Log Likelihood (NLL) 손실 함수를 구현합니다. \n",
    "\n",
    "언어 모델의 목표는 주어진 문장의 확률을 최대화하는 것입니다. 문장의 확률은 각 단어의 조건부 확률의 곱으로 계산할 수 있습니다.\n",
    "\n",
    "$$P(w_1, w_2, \\ldots, w_n) = \\prod_{i=1}^{n} P(w_i | w_{i-1})$$\n",
    "\n",
    "수치적 안정성을 위해 로그 확률을 사용하며, 손실 함수는 음의 로그 확률(Negative Log Likelihood)로 정의됩니다.\n",
    "\n",
    "$$\\text{NLL} = -\\sum_{i=1}^{n} \\log P(w_i | w_{i-1})$$\n",
    "\n",
    "NLL이 낮을수록 모델의 성능이 좋다는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장별 Negative Log Likelihood:\n",
      "문장 1: 자연어 처리는 컴퓨터가 인간의 언어를 이해하고 처리하는 기술입니다, NLL = 23.4995\n",
      "문장 2: 기술입니다 처리하는 이해하고 언어를 인간의 컴퓨터가 처리는 자연어, NLL = 28.6601\n",
      "문장 3: 자연어 처리 기술, NLL = 13.4812\n",
      "문장 4: 인공지능 기술 발전, NLL = 20.0000\n"
     ]
    }
   ],
   "source": [
    "def calculate_nll(sentence, conditional_probabilities, word_to_id):\n",
    "    \"\"\"주어진 문장에 대한 Negative Log Likelihood를 계산하는 함수\n",
    "    \n",
    "    Args:\n",
    "        sentence: 토큰화된 문장\n",
    "        conditional_probabilities: 조건부 확률 행렬\n",
    "        word_to_id: 단어-ID 매핑 딕셔너리\n",
    "        \n",
    "    Returns:\n",
    "        NLL 값\n",
    "    \"\"\"\n",
    "    if len(sentence) < 2:\n",
    "        return float('inf')  # 문장이 너무 짧으면 bigram을 추출할 수 없음\n",
    "    \n",
    "    nll = 0.0\n",
    "    for i in range(1, len(sentence)):\n",
    "        prev_word, curr_word = sentence[i-1], sentence[i]\n",
    "        \n",
    "        # 단어가 어휘 사전에 없는 경우 처리\n",
    "        if prev_word not in word_to_id or curr_word not in word_to_id:\n",
    "            nll += 10.0  # 큰 패널티 부여\n",
    "            continue\n",
    "        \n",
    "        prev_id, curr_id = word_to_id[prev_word], word_to_id[curr_word]\n",
    "        prob = conditional_probabilities[prev_id, curr_id]\n",
    "        \n",
    "        # 확률이 0인 경우 처리 (smoothing)\n",
    "        if prob == 0:\n",
    "            nll += 10.0  # 큰 패널티 부여\n",
    "        else:\n",
    "            nll += -np.log(prob)\n",
    "    \n",
    "    return nll\n",
    "\n",
    "# 예시 문장들에 대한 NLL 계산\n",
    "example_sentences = [\n",
    "    tokenized_corpus[0],  # 실제 말뭉치에서 첫 번째 문장\n",
    "    tokenized_corpus[0][::-1],  # 첫 번째 문장을 역순으로 배열 (이상한 문장)\n",
    "    ['자연어', '처리', '기술'],  # 간단한 문장\n",
    "    ['인공지능', '기술', '발전']  # 다른 간단한 문장\n",
    "]\n",
    "\n",
    "print(\"문장별 Negative Log Likelihood:\")\n",
    "for i, sentence in enumerate(example_sentences):\n",
    "    nll = calculate_nll(sentence, conditional_probabilities, word_to_id)\n",
    "    print(f\"문장 {i+1}: {' '.join(sentence)}, NLL = {nll:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 다음 단어 예측 함수 구현\n",
    "\n",
    "n-gram 모델을 사용하여 주어진 단어 다음에 올 가능성이 높은 단어를 예측하는 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 '상위'를 어휘 사전에서 찾을 수 없습니다.\n",
      "\n",
      "'상위' 다음에 올 가능성이 높은 단어:\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(prev_word, conditional_probabilities, word_to_id, id_to_word, top_n=5):\n",
    "    \"\"\"주어진 단어 다음에 올 가능성이 높은 단어들을 예측하는 함수\n",
    "    \n",
    "    Args:\n",
    "        prev_word: 이전 단어\n",
    "        conditional_probabilities: 조건부 확률 행렬\n",
    "        word_to_id: 단어-ID 매핑 딕셔너리\n",
    "        id_to_word: ID-단어 매핑 딕셔너리\n",
    "        top_n: 상위 몇 개의 예측을 반환할지 결정\n",
    "        \n",
    "    Returns:\n",
    "        예측된 단어와 확률의 리스트\n",
    "    \"\"\"\n",
    "    # 단어가 어휘 사전에 없는 경우 처리\n",
    "    if prev_word not in word_to_id:\n",
    "        print(f\"단어 '{prev_word}'를 어휘 사전에서 찾을 수 없습니다.\")\n",
    "        return []\n",
    "    \n",
    "    prev_id = word_to_id[prev_word]\n",
    "    probs = conditional_probabilities[prev_id]\n",
    "    \n",
    "    # 확률이 높은 상위 top_n개 단어 선택\n",
    "    top_indices = np.argsort(probs)[-top_n:][::-1]\n",
    "    \n",
    "    # 예측 결과 생성\n",
    "    predictions = []\n",
    "    for idx in top_indices:\n",
    "        if probs[idx] > 0:  # 확률이 0인 경우 제외\n",
    "            predictions.append((id_to_word[idx], probs[idx]))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 예시: 특정 단어 다음에 올 가능성이 높은 단어 예측\n",
    "example_words = most_common_words[:2]  # 가장 빈번한 단어 2개\n",
    "for word in example_words:\n",
    "    predictions = predict_next_word(word, conditional_probabilities, word_to_id, id_to_word)\n",
    "    print(f\"\\n'{word}' 다음에 올 가능성이 높은 단어:\")\n",
    "    for next_word, prob in predictions:\n",
    "        print(f\"  {next_word}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 결과 저장\n",
    "\n",
    "후속 분석을 위해 n-gram 모델 결과를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram 모델 결과가 'ngram_results.pkl' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# n-gram 모델 결과 저장\n",
    "ngram_results = {\n",
    "    'bigrams': bigrams,\n",
    "    'trigrams': trigrams,\n",
    "    'cooccurrence_matrix': cooccurrence_matrix,\n",
    "    'conditional_probabilities': conditional_probabilities\n",
    "}\n",
    "\n",
    "with open('ngram_results.pkl', 'wb') as f:\n",
    "    pickle.dump(ngram_results, f)\n",
    "\n",
    "print(\"n-gram 모델 결과가 'ngram_results.pkl' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 요약 및 다음 단계\n",
    "\n",
    "이 노트북에서는 n-gram 기반 통계 언어 모델을 구현했습니다. 주요 단계는 다음과 같습니다:\n",
    "\n",
    "1. n-gram 추출 함수 구현\n",
    "2. 동시출현 행렬(co-occurrence matrix) 구축\n",
    "3. 조건부 확률 $P(w_i | w_{i-1})$ 계산\n",
    "4. 조건부 확률 시각화 및 테이블 표시\n",
    "5. Negative Log Likelihood Loss 구현\n",
    "6. 다음 단어 예측 함수 구현\n",
    "\n",
    "n-gram 모델은 단순하지만 효과적인 통계적 언어 모델입니다. 그러나 어휘 크기가 커지면 희소성 문제가 발생하며, 장거리 의존성을 포착하기 어렵다는 한계가 있습니다.\n",
    "\n",
    "다음 노트북에서는 GloVe 임베딩을 구현하여 이러한 한계를 극복해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제\n",
    "\n",
    "1. 다양한 n 값(n=1, 2, 3)에 대해 n-gram을 추출하고, 생성된 n-gram 분포를 비교해보세요.\n",
    "→ 단어 조합 다양성 및 빈도 패턴 변화 관찰\n",
    "\n",
    "2. 구축한 동시출현 행렬을 시각화하여 자주 등장하는 단어쌍을 파악해보세요.\n",
    "→ 문맥에서 강하게 연결된 단어쌍 확인\n",
    "\n",
    "3. 조건부 확률 $P(w_i | w_{i-1})$을 기반으로, 주어진 문장에서 다음 단어를 예측해보세요.\n",
    "→ 모델의 확률 기반 추론 능력 확인\n",
    "\n",
    "4. Negative Log Likelihood Loss를 적용하여 문장의 확률을 계산하고, 문장별 품질을 비교해보세요.\n",
    "→ 확률적 언어 모델로서의 성능 평가 연습\n",
    "\n",
    "5. n-gram 모델의 한계(희소성, 장거리 의존성 문제)를 경험할 수 있는 예시 문장을 만들어보세요.\n",
    "→ 다음 단계(GloVe, 신경망 등)로의 필요성 체감"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
